{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Story Generator"
   ],
   "metadata": {
    "id": "b7077488"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Ready"
   ],
   "metadata": {
    "id": "60b8dfc3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 기본 패키지 임포트"
   ],
   "metadata": {
    "id": "28a05a6e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import GPT2LMHeadModel"
   ],
   "outputs": [],
   "metadata": {
    "id": "a4c51c98"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 학습 모델 다운로드"
   ],
   "metadata": {
    "id": "cf126c75"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "MODEL_NAME = \"skt/kogpt2-base-v2\""
   ],
   "outputs": [],
   "metadata": {
    "id": "35e0ec56"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 토크나이저 load"
   ],
   "metadata": {
    "id": "57aa65ec"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "TOKENS_DICT = {\n",
    "    'bos_token':'<s>',\n",
    "    'eos_token':'</s>',\n",
    "    'unk_token':'<unk>',\n",
    "    'pad_token':'<pad>',\n",
    "    'mask_token':'<mask>'\n",
    "}\n",
    "\n",
    "# 특수 토큰이 토크나이저에 추가되고 모델은 수정된 토크나이저에 맞게 임베딩의 크기를 조정\n",
    "tokenizer.add_special_tokens(TOKENS_DICT)\n",
    "\n",
    "print(tokenizer.special_tokens_map)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>'}\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fffd83bb",
    "outputId": "8ab92b3b-7fe0-4e96-e6c8-50fc59e0ff73"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 미세조정학습 모델 load"
   ],
   "metadata": {
    "id": "424e1abc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from util.generator import sample_sequence as gen\n",
    "from util.model import model_loading as load"
   ],
   "outputs": [],
   "metadata": {
    "id": "175de497"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "checkpointPath = \"./modelCheckpoint/talestart1890w.tar\"\n",
    "loading = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model,ckp = load(checkpointPath, PU = 'cpu', status = loading)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(ckp['epoch'], ckp['loss'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2000 tensor(0.0307, requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "vocab_path = \"./data/정제/index_tale_plus_novel.txt\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "p1, p2, p3 = 1,2,1\n",
    "\n",
    "max_sent = [p1,p2//2, p2//2 ,p3]\n",
    "\n",
    "context = \"어제\"\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from util.generator import sample_sequence\n",
    "from util.similarity import similarity"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "\n",
    "# 1번 문단 생성\n",
    "print(\"1번째 문단\")\n",
    "result = []\n",
    "p = sample_sequence(\n",
    "    vocab=vocab_path,\n",
    "    model=model, \n",
    "    length = max_sent[0]*30,\n",
    "    context=context,\n",
    "    num_samples=1, \n",
    "    repetition_penalty=2.0,\n",
    "    top_p=0.9,\n",
    "    tokenizer = tokenizer)\n",
    "p = tokenizer.decode(p[0,:].tolist())\n",
    "result.append(p)\n",
    "\n",
    "# 2~4번 문단 생성\n",
    "for i in range(len(max_sent[1:])):\n",
    "    print(f\"{i+2}번째 문단\")\n",
    "    sim = 0\n",
    "    while(sim < 0.02):\n",
    "        next_p = sample_sequence(\n",
    "            vocab=vocab_path,\n",
    "            model=model, \n",
    "            length=max_sent[i+1]*30,\n",
    "            context=p, \n",
    "            num_samples=1, \n",
    "            repetition_penalty=2.0,\n",
    "            top_p=0.9,\n",
    "            tokenizer = tokenizer)\n",
    "        next_p = tokenizer.decode(next_p[0,:].tolist())\n",
    "        sim = similarity(p, next_p)\n",
    "        print(sim)\n",
    "\n",
    "    result.append(next_p)\n",
    "    p = next_p"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1번째 문단\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "31it [00:03,  8.31it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word not in corpus => 0 skipped\n",
      "2번째 문단\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "31it [00:07,  4.41it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word not in corpus => 0 skipped\n",
      "0.5680726713888613\n",
      "3번째 문단\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "31it [00:12,  2.51it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word not in corpus => 4 skipped\n",
      "0.7499191438281658\n",
      "4번째 문단\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "31it [00:13,  2.25it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Word not in corpus => 0 skipped\n",
      "0.8010912403995811\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "story generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "c84ec5531762457a514972294189478bb2b86b2856b4d2c66c8829aed73cefe4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}